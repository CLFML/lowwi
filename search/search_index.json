{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Hi Welcome to the Lowwi project! This project aims to provide users with a (easily) optimizable lightweight runtime for wakewords using the openwakeword architecture.</p> <p>Head over to Getting Started and kickstart your wakeword journey :)</p>"},{"location":"about/implementation/","title":"Library implementation details","text":"<p>Here some brief details as how the library is implemented;</p>"},{"location":"about/implementation/#architecture","title":"Architecture","text":"<p>The whole runtime consists of three stages:</p> <ol> <li> <p>Melspectrogram; A pre-processing model that computes a melspectrogram of the input audio data. This library uses an ONNX implementation of Torch's melspectrogram function with fixed parameters which enables efficient performance across devices. This onnx model is provided by dscripka.</p> </li> <li> <p>Embedding/feature generation; A shared feature extraction backbone model that converts melspectrogram inputs into general-purpose speech audio embeddings. This model is provided by Google as a TFHub module under an Apache-2.0 license. For openWakeWord, this model was manually re-implemented to separate out different functionality and allow for more control of architecture modifications compared to a TFHub module. The model itself is series of relatively simple convolutional blocks, and gains its strong performance from extensive pre-training on large amounts of data. This model is the core component of openWakeWord, and enables the strong performance that is seen even when training on fully-synthetic data.</p> </li> <li> <p>Feature Classification: A classification model that follows the shared (and frozen) feature extraction model. The structure of this classification model is arbitrary, but in practice a simple fully-connected network or 2 layer RNN works well.</p> </li> </ol>"},{"location":"about/implementation/#code-implementation","title":"Code implementation","text":"<p>The general architecture of openwakeword is also reflected in to the code. Each class is one of the stages, and runs one model:</p> <ul> <li> <p>Class: Melspectrogram -&gt; Runs melspectrogram stage</p> </li> <li> <p>Class: Embedding -&gt; Runs embedding stage</p> </li> <li> <p>Class: WakeWord -&gt; Runs classifier stage</p> </li> </ul> <p>Yes, it is that simple! the Lowwi class itself contains some glue logic that controls the pipeline and calls the right callback functions when classifier model detects wakeword.</p> <p>For example see the Lowwi-&gt;Run function:</p> <pre><code>void Lowwi::run(const std::vector&lt;float&gt; &amp;audio_samples)\n{\n    if(audio_samples.empty()) {\n       return; /* No samples */\n    }\n\n    _mel_samples = _mel-&gt;convert(std::ref(audio_samples));\n    _feature_samples = _emb-&gt;convert(std::ref(_mel_samples));\n    /* Loop through the classifier models */\n    for (auto &amp;ww : _wakewords) {\n        wakeword_result res = ww.ww_inst-&gt;detect(_feature_samples);\n        /* Check if wakeword is triggered */\n        if(res.detected) {\n            /* \n             * Wakeword triggered!\n             * Construct context variable\n             * with the triggered wakeword phrase &amp; confidence factor \n             */\n            Lowwi_ctx_t cb = {ww.properties.phrase, res.confidence};\n            /* Run callback function */\n            ww.properties.cbfunc(cb, ww.properties.cb_arg);\n        }\n    }\n    /* Clear all processed Melspectrogram &amp; feature samples */\n    _mel_samples.resize(0);\n    _feature_samples.resize(0);\n}   \n</code></pre> <p>It just runs the steps followed by looping through all registered classifier models. When a wakeword is detected (<code>res.detected</code>) it runs the callback function(<code>ww.properties.cbfunc()</code>).</p>"},{"location":"about/implementation/#design-decisions","title":"Design decisions","text":"<p>Design decisions that were made (some might change!):</p> <ul> <li> <p>Everything was designed single threaded (as the biggest c++ alternative of this library, used so much threading it slowed down the code drastically).   Although for small amount of wakewords &lt; 10 it is faster, over &gt; 10 it might be slower or as fast.</p> </li> <li> <p>ONNX is used instead of liteRT, even though both are supported by openwakeword project. ONNX has been proven to be faster for this model. The only thing it might hinder is using the Coral edge tpu which is liteRT only.</p> </li> </ul>"},{"location":"about/implementation_ros/","title":"ROS 2 Lowwi Wakeword Detection Node","text":"<p>A ROS 2 node that listens to audio input and detects custom wakewords using the Lowwi library. Triggers a callback and publishes detection results when a wakeword is detected.</p>"},{"location":"about/implementation_ros/#topics","title":"\u2705 Topics","text":"Topic Type Description <code>/audio_stamped</code> (default) <code>audio_tools/msg/AudioDataStamped</code> Raw audio input in S16LE format <code>/lowwi_ww</code> (default) <code>lowwi/msg/WakeWord</code> Published when a wakeword is detected"},{"location":"about/implementation_ros/#parameters","title":"\u2699\ufe0f Parameters","text":"Parameter Type Description <code>audio_topic</code> <code>string</code> Topic to subscribe to for audio input (default: <code>/audio_stamped</code>) <code>output_topic</code> <code>string</code> Topic to publish wakeword detection messages (default: <code>/lowwi_ww</code>) <code>wakeword.phrases</code> <code>string[]</code> List of phrases to detect (e.g. <code>[\"Hey Jarvis\"]</code>) <code>wakeword.models</code> <code>string[]</code> Path to corresponding ONNX model files <code>wakeword.min_activations</code> <code>int[]</code> (optional) Minimum activations to trigger wakeword (default: <code>5</code> if omitted) <code>wakeword.refractory</code> <code>int[]</code> (optional) Refractory period (cooldown) per wakeword (default: <code>20</code>) <code>wakeword.threshold</code> <code>float[]</code> (optional) Confidence threshold per wakeword (default: <code>0.5</code>)"},{"location":"about/implementation_ros/#implementation-notes","title":"\ud83e\udde9 Implementation Notes","text":"<ul> <li>Written in C++ using <code>rclcpp</code>.</li> <li>Subscribes to incoming audio with S16LE at 16kHz</li> <li>Uses CLFML::LOWWI to manage wakeword detection.</li> <li>Wakewords and model settings are loaded at runtime via parameters.</li> <li>Gracefully handles missing optional parameters by applying sensible defaults.</li> </ul>"},{"location":"about/implementation_ros/#wakeword-message-structure","title":"\ud83d\udce4 WakeWord Message Structure","text":"<p>Published to <code>/lowwi_ww</code> (or a user-defined topic), of type <code>lowwi/msg/WakeWord</code>:</p> Field Type Description <code>header.stamp</code> <code>builtin_interfaces/Time</code> Timestamp of the triggering audio sample <code>header.frame_id</code> <code>string</code> Frame from which the audio was captured <code>wakeword_detected</code> <code>bool</code> Always <code>true</code> when message is published <code>wakeword_name</code> <code>string</code> Name/phrase of the detected wakeword <code>wakeword_confidence</code> <code>float32</code> Detection confidence (0.0 \u2013 1.0)"},{"location":"about/implementation_ros/#run-example","title":"\ud83c\udfc1 Run Example","text":"<pre><code>ros2 run lowwi lowwi_node \\\n  --ros-args \\\n  -p wakeword.phrases:=\"['Hey Mycroft', 'Hey Jarvis']\" \\\n  -p wakeword.models:=\"['models/hey_mycroft.onnx', 'models/hey_jarvis.onnx']\" \\\n  -p wakeword.min_activations:=\"[2, 3]\" \\\n  -p wakeword.refractory:=\"[25, 30]\" \\\n  -p wakeword.threshold:=\"[0.6, 0.65]\" \\\n  -p audio_topic:=\"/my_custom_audio\" \\\n  -p output_topic:=\"/custom_wakeword_output\"\n</code></pre>"},{"location":"contributing/license/","title":"License","text":"<p>This work is licensed under the apache-2.0 license.</p>"},{"location":"contributing/rules/","title":"Contribution rules","text":"<p>For contributing we recommend creating a fork and when ready a pull request to merge the changes with this repository.  In the pull request please state:</p> <ul> <li>What has been added/changed?</li> <li>Some reasoning about implementation details</li> </ul> <p>Please don't do refactors without consent of administrators  as we will not merge them."},{"location":"contributing/rules/#new-features","title":"New features","text":"<p>If you have any cool feature/idea to add to the code, please start an issue in GitHub to introduce the idea to the maintainers.</p>"},{"location":"usage/lowwi_demo/","title":"LOWWI demo fragment","text":"<p>The Lowwi fragment Demo that comes with this library demonstrates the wakeword api of this library without a microphone. It uses a prerecorded .wav file with the \"Hey mycroft\" wakeword. To trigger the \"Hey mycroft\" wakeword.</p>"},{"location":"usage/lowwi_demo/#building-and-compiling","title":"Building and compiling","text":"<p>To build and run this example you need all the prerequisites you would normally need to build the library. As these steps differ a lot between platforms/oses, a guide for the three most used platforms was made:</p> <ul> <li>Windows Guide</li> <li>Mac Os Guide</li> <li>Linux Guide</li> </ul>"},{"location":"usage/lowwi_demo_mic/","title":"LOWWI demo microphone","text":"<p>The Lowwi microphone Demo that comes with this library demonstrates the wakeword api of this library by letting you test it with your microphone. You can now trigger the \"Hey mycroft\" wakeword, by screaming it at your screen! Watch out for any house mates, you might get strange looks. </p>"},{"location":"usage/lowwi_demo_mic/#building-and-compiling","title":"Building and compiling","text":"<p>To build and run this example you need all the prerequisites you would normally need to build the library. As these steps differ a lot between platforms/oses, a guide for the three most used platforms was made:</p> <ul> <li>Windows Guide</li> <li>Mac Os Guide</li> <li>Linux Guide</li> </ul>"},{"location":"usage/overview/","title":"Overview","text":"<p>The library offers a relatively simple abstraction for use with self-trained openwakeword models.</p>"},{"location":"usage/overview/#api","title":"API","text":"<p>The library API consists of the following functions: <pre><code>namespace CLFML::LOWWI {\n\n/**\n * @brief The user-provided struct which provides the classifier model settings\n * @param phrase The model identifier which get's passed into the callback function when triggered.\n * @param model_path The classifier model path\n * @param cbfunc Function pointer to a callback function that get's called when wakeword is triggered\n * @param cb_arg Additional function argument that get's passed in the callback when wakeword is triggered\n *               (void pointer)\n * @param refractory The negative feedback on activation, when activated this factor makes the debouncing work :)\n *                   Increasing it gives a higher negative bounty, thus dampening any further activations.\n *                   (Default = 20)\n *\n * @param threshold The threshold determines whether model confidence is worth acting on (default = 0.5f)\n * @param min_activations Number of activations the model should have to be considered detected\n *                       (Default = 5, but depends on how well the model is trained and how easy to detect)\n *                       (It's like a debouncing system)\n */\nstruct Lowwi_word_t\n{\n    std::string phrase = \"\";\n    std::filesystem::path model_path = std::filesystem::path(\"\");\n    std::function&lt;void(Lowwi_ctx_t, std::shared_ptr&lt;void&gt;)&gt; cbfunc = nullptr;\n    std::shared_ptr&lt;void&gt; cb_arg = nullptr;\n    int refractory = 20;\n    float threshold = 0.5f;\n    uint8_t min_activations = 5;\n    uint8_t debug = false;\n};\n\n/**\n* @brief Add new wakeword to detection runtime\n* @param lowwi_word Struct with the properties \n*                   of the to be added wakeword\n*/\nvoid Lowwi::add_wakeword(const Lowwi_word_t&amp; lowwi_word);\n\n/**\n* @brief Remove wakeword from detection runtime\n* @param model_path Model path of the to be removed wakeword\n*/\nvoid remove_wakeword(std::filesystem::path model_path);\n\n/**\n* @brief Runs wakeword detection runtime on audio samples\n* @param audio_samples Audio samples to parse\n*/\nvoid Lowwi::run(const std::vector&lt;float&gt; &amp;audio_samples);\n}\n</code></pre> The comments above the functions describe fairly well what each function does. Here some additional notes;</p>"},{"location":"usage/overview/#cmake-integration","title":"CMake integration","text":"<p>This project uses CMake for generating the build files. The CMakeLists is configured as follows:</p>"},{"location":"usage/overview/#targets","title":"Target(s)","text":"<p>The main target defined in the CMakeLists is the <code>Lowwi</code> target. As this will not be the only library released under the CLFML organisation, we chose to namespace it and call it <code>CLFML::Lowwi</code>. </p> <p>Other targets which are defined in the CMake files of this project are the Unit tests.</p>"},{"location":"usage/overview/#configuration-options","title":"Configuration options","text":"<p>Some of the configuration options which can be used to generate the CMake project are:</p> <ul> <li><code>CLFML_FACE_DETECTOR_BUILD_EXAMPLE_PROJECTS</code>; Build example projects (fragment &amp; mic demo) (Default=ON, *only when project is not part of other project)</li> </ul>"},{"location":"usage/overview/#integrating-it-into-your-own-project","title":"Integrating it into your own project","text":"<p>Here are some CMake snippets which indicate how this project might be included into your own CMake project.</p> <p>Automatically fetching from GitHub</p> <p>CPU only: <pre><code>include(FetchContent)\n\nFetchContent_Declare(\n Lowwi\n GIT_REPOSITORY https://github.com/CLFML/lowwi.git\n GIT_TAG        main\n)\nFetchContent_MakeAvailable(Lowwi)\n\n...\n\ntarget_link_libraries(YOUR_MAIN_EXECUTABLE_NAME CLFML::Lowwi)\n</code></pre></p> <p>Manually using add_subdirectory</p> <p>First make sure that this library is cloned into the project directory!     CPU only: <pre><code>add_subdirectory(lowwi)\n...\n\ntarget_link_libraries(YOUR_MAIN_EXECUTABLE_NAME CLFML::Lowwi)\n</code></pre></p>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/","title":"Getting started with Pixi","text":"<p>Pixi makes cross-platform ROS 2 development easy. You can build and run both capture and playback nodes on Linux and Windows\u2014with no system-wide ROS install.</p>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#node-details","title":"Node details","text":"<p>For more details about the node see: ROS2 Lowwi Wakeword Detection Node page in implementation tab</p>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#install-pixi","title":"\ud83d\udce6 Install Pixi","text":"<p>Linux:</p> <pre><code>curl -fsSL https://pixi.sh/install.sh | bash\n</code></pre> <p>Windows (PowerShell):</p> <pre><code>powershell -ExecutionPolicy ByPass -c \"irm -useb https://pixi.sh/install.ps1 | iex\"\n</code></pre>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#clone-build-project","title":"\ud83d\ude80 Clone &amp; Build Project","text":"<pre><code>git clone https://github.com/CLFML/lowwi.git\ncd lowwi\npixi install\npixi run build\n</code></pre> <p>Or launch VSCode with the environment:</p> <pre><code>pixi run vscode\n</code></pre> <p>\u2705 Note (Windows): Always build in Release or RelWithDebInfo, not Debug! (Ctrl+Shift+P \u2192 \"CMake: Select Variant\")</p>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#using-as-a-pixi-dependency","title":"\u26a1 Using as a Pixi Dependency","text":"<p>Want to use <code>custom_pkg</code> from another Pixi-based project?</p>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#1-init-a-new-project","title":"1. Init a new project","text":"<pre><code>mkdir my_project &amp;&amp; cd my_project\npixi init\n</code></pre>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#2-edit-pixitoml","title":"2. Edit <code>pixi.toml</code>","text":"<p>Add these:</p> <pre><code>[project]\nchannels = [\n  \"https://fast.prefix.dev/conda-forge\",\n  \"https://prefix.dev/robostack-jazzy\",\n  \"https://clfml.github.io/conda_ros2_jazzy_channel/\"\n]\n\n[dependencies]\nros-jazzy-ros-base = \"*\"\nros-jazzy-audio-tools = \"*\"\nros-jazzy-lowwi = \"*\"\ncolcon-common-extensions = \"*\"\nrosdep = \"*\"\n</code></pre>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#optional-vscode-support","title":"\ud83e\udde0 Optional: VSCode Support","text":"<p>Add to your <code>pixi.toml</code>:</p> <pre><code>[target.linux-64.dependencies]\npython-devtools = \"*\"\npybind11 = \"*\"\nnumpy = \"*\"\n\n[target.win-64.dependencies]\npython-devtools = \"*\"\n\n[target.linux-64.tasks]\nvscode = 'env -u LD_LIBRARY_PATH code .'\n\n[target.win-64.tasks]\nvscode = \"code .\"\n</code></pre>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#3-run-the-node","title":"3. Run the node","text":"<pre><code>pixi install\n# Copy the models dir from Lowwi Git repo to your own project folder\npixi shell\n# run this command to launch lowwi node with default models:\nros2 run lowwi lowwi_node \\\n  --ros-args \\\n  -p wakeword.phrases:=\"['Hey Mycroft', 'Hey Jarvis']\" \\\n  -p wakeword.models:=\"['models/example_wakewords/hey_mycroft.onnx', 'models/example_wakewords/hey_jarvis.onnx']\" \\\n  -p wakeword.min_activations:=\"[2, 2]\"\n</code></pre>"},{"location":"usage/build_environment/ros2_pixi_build_linux_windows/#35-run-the-node-with-launch-file","title":"3.5 Run the node with launch-file","text":"<p>For automation purposes you can use a launch-file (\"lowwi_launch.py\") like this:</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='lowwi',\n            executable='lowwi_node',\n            name='lowwi_node',\n            output='screen',\n            parameters=['params.yaml']  # Path to your params file\n        )\n    ])\n</code></pre> <p>with <code>params.yaml</code> file: <pre><code>lowwi_node:\n  ros__parameters:\n    wakeword.phrases: [\"Hey Mycroft\", \"Hey Jarvis\"]\n    wakeword.models: [\"models/example_wakewords/hey_mycroft.onnx\", \"models/example_wakewords/hey_jarvis.onnx\"]\n    wakeword.min_activations: [2,2]\n</code></pre> In <code>pixi shell</code> run:</p> <pre><code>ros2 launch lowwi_launch.py\n</code></pre>"},{"location":"usage/build_environment/usage_with_linux/","title":"Set-up build environment on Linux","text":"<p>Linux is one of the easiest os'es to set-up as most packages and libraries can be found in the package repositories.</p>"},{"location":"usage/build_environment/usage_with_linux/#ubuntu-and-debian","title":"Ubuntu and Debian","text":"<pre><code>sudo apt-get update &amp;&amp; sudo apt-get install build-essential cmake ninja-build libsdl2-2.0-0 libsdl2-dev\n</code></pre> <p>If you have not installed VSCode yet, do not install using APT in ubuntu as it will install the sandboxed snap version.</p> <p>Which has many issues due to the sandbox environment</p> <p>Use this guide instead, which installs it using the APT repository from Microsoft themselves.</p>"},{"location":"usage/build_environment/usage_with_linux/#arch","title":"Arch","text":"<pre><code>sudo pacman -S sdl2 cmake gcc ninja\n</code></pre> <p>If you have not installed VSCode yet,</p> <p>Install the <code>visual-studio-code-bin</code> package from AUR.</p>"},{"location":"usage/build_environment/usage_with_linux/#fedora","title":"Fedora","text":"<pre><code>sudo dnf install SDL2-devel gcc cmake ninja\n</code></pre> <p>If you have not installed VSCode yet, use this guide.</p>"},{"location":"usage/build_environment/usage_with_linux/#compiling-and-running-the-example","title":"Compiling and running the example","text":"<p>The library contains an example demonstrating the usage and functionality of this library. </p> <p>To compile and run this example:</p> <ol> <li> <p>Clone this repo: <pre><code>git clone https://github.com/CLFML/lowwi.git\n</code></pre></p> </li> <li> <p>Open the cloned repo folder in vscode; <code>File-&gt;Open Folder</code></p> </li> <li> <p>Select Ninja as build generator by pressing CRTL+SHIFT+P-&gt;\"CMake: Open CMake Tools Extension Settings\"-&gt;\"@ext:ms-vscode.cmake-tools generator\"    Now type Ninja (with capital N into the generator field!).    </p> </li> <li> <p>Select the <code>GCC kit</code>by pressing CTRL+SHIFT+p and selecting <code>CMake: Select a kit</code>.    </p> </li> <li> <p>CMake will now configure; By default it will configure as Debug build, this has a significant performance hit.    To change to release with debug info (which has optimizations turned on, but is still debuggable). Press CTRL+SHIFT+p again and enter <code>CMake: Select Variant</code>-&gt; <code>RelWithDebInfo</code> </p> </li> <li> <p>Let CMake Finish configuring your build configuration. Then click on the Play button on the blue bar on the bottom of screen, CMake might ask which target to launch, select the <code>LOWWI_demo_mic</code> target.    </p> </li> <li> <p>After build is finished, it will launch the demo which uses your microphone to detect the \"Hey Mycroft\" wakeword.</p> </li> </ol>"},{"location":"usage/build_environment/usage_with_mac/","title":"Set-up build environment on Mac Os","text":"<p>For Mac os it is easier to use Brew (community-based package manager). </p> <p>With Brew installed it is relatively easy as it requires one command to install all the required packages and libraries.</p>"},{"location":"usage/build_environment/usage_with_mac/#installing-brew","title":"Installing Brew","text":"<p>Follow the instructions on the webpage.</p>"},{"location":"usage/build_environment/usage_with_mac/#installation-of-packages-and-libraries","title":"Installation of packages and libraries","text":"<p>The command for installing the packages and libraries:</p> <pre><code>brew install cmake gcc cmake sdl2 ninja\n</code></pre>"},{"location":"usage/build_environment/usage_with_mac/#installing-vscode","title":"Installing VSCode","text":"<p>Follow the instructions on the VSCode website.</p>"},{"location":"usage/build_environment/usage_with_mac/#compiling-and-running-the-example","title":"Compiling and running the example","text":"<p>The library contains an example demonstrating the usage and functionality of this library. </p> <p>To compile and run this example:</p> <ol> <li> <p>Clone this repo: <pre><code>git clone https://github.com/CLFML/lowwi.git\n</code></pre></p> </li> <li> <p>Open the cloned repo folder in vscode; <code>File-&gt;Open Folder</code></p> </li> <li> <p>Select Ninja as build generator by pressing CRTL+SHIFT+P-&gt;\"CMake: Open CMake Tools Extension Settings\"-&gt;\"@ext:ms-vscode.cmake-tools generator\"    Now type Ninja (with capital N into the generator field!).    </p> </li> <li> <p>Select the <code>GCC kit</code>by pressing CTRL+SHIFT+p and selecting <code>CMake: Select a kit</code>.</p> </li> <li> <p>CMake will now configure; By default it will configure as Debug build, this has a significant performance hit.    To change to release with debug info (which has optimizations turned on, but is still debuggable). Press CTRL+SHIFT+p again and enter <code>CMake: Select Variant</code>-&gt; <code>RelWithDebInfo</code> </p> </li> <li> <p>Let CMake Finish configuring your build configuration. Then click on the Play button on the blue bar on the bottom of screen, CMake might ask which target to launch, select the <code>LOWWI_demo_mic</code> target.    </p> </li> <li> <p>After build is finished, it will launch the demo which uses your microphone to detect the \"Hey Mycroft\" wakeword.</p> </li> </ol>"},{"location":"usage/build_environment/usage_with_native_linux/","title":"\ud83d\udc27 Getting Started with Native ROS","text":"<p>Prefer a traditional system-wide install? Use the prebuilt <code>.deb</code> package for Ubuntu Noble / ROS 2 Jazzy.</p>"},{"location":"usage/build_environment/usage_with_native_linux/#node-details","title":"Node details","text":"<p>For more details about the node see: ROS2 Lowwi Wakeword Detection Node page in implementation tab</p>"},{"location":"usage/build_environment/usage_with_native_linux/#install-package-via-deb","title":"\ud83d\udce6 Install package via <code>.deb</code>","text":"<p>Install the latest <code>.deb</code> package directly from Releases:</p> <pre><code>curl -s https://api.github.com/repos/CLFML/lowwi/releases/latest \\\n  | grep \"browser_download_url.*deb\" \\\n  | cut -d : -f 2,3 \\\n  | tr -d \\\" \\\n  | wget -qi -\nsudo dpkg -i ./ros-jazzy-*.deb\n</code></pre>"},{"location":"usage/build_environment/usage_with_native_linux/#run-the-nodes","title":"\u2705 Run the Nodes","text":"<p>Make sure ROS is sourced:</p> <p><pre><code>source /opt/ros/jazzy/setup.sh\n</code></pre> Then copy the models dir from Lowwi Git repo to your own project folder</p> <p>When model dir present run the node:</p> <p>First run the audio_capture_node</p> <pre><code>ros2 run audio_tools audio_capture_node\n</code></pre> <pre><code># run this command to launch lowwi node with default models:\nros2 run lowwi lowwi_node \\\n  --ros-args \\\n  -p wakeword.phrases:=\"['Hey Mycroft', 'Hey Jarvis']\" \\\n  -p wakeword.models:=\"['models/example_wakewords/hey_mycroft.onnx', 'models/example_wakewords/hey_jarvis.onnx']\" \\\n  -p wakeword.min_activations:=\"[2, 2]\"\n</code></pre>"},{"location":"usage/build_environment/usage_with_native_linux/#35-run-the-node-with-launch-file","title":"3.5 Run the node with launch-file","text":"<p>For automation purposes you can use a launch-file (\"lowwi_launch.py\") like this:</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='lowwi',\n            executable='lowwi_node',\n            name='lowwi_node',\n            output='screen',\n            parameters=['params.yaml']  # Path to your params file\n        )\n    ])\n</code></pre> <p>with <code>params.yaml</code> file: <pre><code>lowwi_node:\n  ros__parameters:\n    wakeword.phrases: [\"Hey Mycroft\", \"Hey Jarvis\"]\n    wakeword.models: [\"models/example_wakewords/hey_mycroft.onnx\", \"models/example_wakewords/hey_jarvis.onnx\"]\n    wakeword.min_activations: [2,2]\n</code></pre> In <code>sourced shell</code> run:</p> <pre><code>ros2 launch lowwi_launch.py\n</code></pre>"},{"location":"usage/build_environment/usage_with_windows/","title":"Set-up build environment on Windows","text":"<p>Before you can compile and run the demo you need to install the following tools and libraries:</p> <ul> <li>Any C/C++ compiler (MSVC is recommended, but GCC works as well)</li> <li>CMake</li> <li>Ninja (Optional, but recommended as generating for MSBuild is very slow!)</li> <li>Any code editor (This guide will use VSCode, as it is free and easy to configure with CMake)</li> </ul> <p>Note</p> <p>Although any recent enough C/C++ compiler can be used. </p> <p>This guide will only use the MSVC compiler!</p> <p>This choice was made as this compiler is also used for all other CLFML projects.</p>"},{"location":"usage/build_environment/usage_with_windows/#installing-msvc16-2019-edition-cmake","title":"Installing MSVC16 (2019 edition) &amp; CMake","text":"<p>The MSVC compiler (and CMake) can be installed by either installing VS BuildTools or Visual Studio 2019.</p> <p>This guide will use the VS BuildTools method, as we don't need the Visual Studio IDE.</p> <p>There are multiple ways you can download and install VS BuildTools 2019;</p> <ul> <li>Manually downloading and installing using this link</li> <li>Using chocolatey:   <code>choco install visualstudio2019buildtools</code></li> <li>Using winget: <code>winget install --id=Microsoft.VisualStudio.2019.BuildTools  -e</code></li> </ul>"},{"location":"usage/build_environment/usage_with_windows/#manually-installing-vs-build-tools-2019","title":"Manually installing VS Build Tools 2019","text":"<ol> <li>Download and run this installer.</li> <li>Select these options: </li> <li>After installation, reboot your machine!</li> </ol>"},{"location":"usage/build_environment/usage_with_windows/#installing-ninja","title":"Installing Ninja","text":"<ol> <li>Download the latest Ninja release for Windows!</li> <li>Unzip this ninja-win.zip to <code>C:\\ninja-win</code></li> <li>Open the environment variables editor using the Windows Startup Menu (Try this guide if you can't find it)</li> <li>Add the <code>C:\\ninja-win</code> path to the PATH variable;</li> <li>Open a commandline window and check if Ninja is correctly installed by running the <code>ninja</code> command!</li> </ol>"},{"location":"usage/build_environment/usage_with_windows/#installing-vscode-with-plugins","title":"Installing VSCode (with plugins)","text":"<p>VSCode is an easy to use code-editor with CMake support (using the CMake Tools plugin). </p> <p>To set-up VSCode the follow these steps:</p> <ol> <li>Download and install VSCode using the installer</li> <li>Follow the initial set-up wizard in vscode (if freshly installed)</li> <li>Download and install this plugin pack:<ul> <li>C/C++ Extension Pack (Microsoft)</li> </ul> </li> </ol>"},{"location":"usage/build_environment/usage_with_windows/#compiling-and-running-the-example","title":"Compiling and running the example","text":"<p>The library contains an example demonstrating the usage and functionality of this library. </p> <p>To compile and run this example:</p> <ol> <li> <p>Clone this repo: <pre><code>git clone https://github.com/CLFML/lowwi.git\n</code></pre></p> </li> <li> <p>Open the cloned repo folder in vscode; <code>File-&gt;Open Folder</code></p> </li> <li> <p>Select Ninja as build generator by pressing CRTL+SHIFT+P-&gt;\"CMake: Open CMake Tools Extension Settings\"-&gt;\"@ext:ms-vscode.cmake-tools generator\"    Now type Ninja (with capital N into the generator field!).    </p> </li> <li> <p>Select the <code>MSVC amd64 kit</code>by pressing CTRL+SHIFT+p and selecting <code>CMake: Select a kit</code>.</p> </li> <li> <p>CMake will now configure; By default it will configure as Debug build, this has a significant performance hit.    To change to release with debug info (which has optimizations turned on, but is still debuggable). Press CTRL+SHIFT+p again and enter <code>CMake: Select Variant</code>-&gt; <code>RelWithDebInfo</code> </p> </li> <li> <p>Let CMake Finish configuring your build configuration. Then click on the Play button on the blue bar on the bottom of screen, CMake might ask which target to launch, select the <code>Lowwi_demo_mic</code> target.    </p> </li> <li> <p>After build is finished, it will launch the demo which uses your microphone to detect the \"Hey Mycroft\" wakeword.</p> </li> </ol>"}]}